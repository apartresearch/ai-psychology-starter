{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Getting information out of text\n","\n","This is a general script to extract information out of text. This is very relevant for analyzing the language model output from your experiments. See [this lecture](https://www.youtube.com/watch?v=7YacOe4XwhY&ab_channel=MachineLearningTV) for information about which types are used and the concepts in natural-language processing.\n","\n","See these tutorials for other tutorials:\n","- [Classifying texts](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py)\n","- [Clustering texts into different topics](https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py)\n","- [Topic extraction from a text collection (corpus)](https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py)"],"metadata":{"id":"ghBw1BdV1Yu0"}},{"cell_type":"markdown","source":["## Count frequency of terms"],"metadata":{"id":"bsY4rUtG3OnZ"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","import pandas as pd\n","\n","# Sample sentences.\n","sentences = [\n","    \"This is a sample sentence\",\n","    \"I am interested in good politics\",\n","    \"You are a very good software engineer, engineer.\",\n","]\n","\n","# Create CountVectorizer, which create bag-of-words model.\n","# stop_words : Specify language to remove stopwords. \n","vectorizer = CountVectorizer(stop_words='english')\n","\n","# Learn vocabulary in sentences. \n","vectorizer.fit(sentences)\n","\n","# Get dictionary. \n","vectorizer.get_feature_names()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a93ERs58zq0a","executionInfo":{"status":"ok","timestamp":1664365337218,"user_tz":-120,"elapsed":244,"user":{"displayName":"Esben Kran","userId":"05753607224872913825"}},"outputId":"ee26710b-1dff-4ef2-b5b3-0f0a143da010"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["['engineer',\n"," 'good',\n"," 'interested',\n"," 'politics',\n"," 'sample',\n"," 'sentence',\n"," 'software']"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["## Evaluate term frequency minus inverse document frequency (TF-IDF)\n","\n","Allows you to see which words are meaningfully frequent. Ignores unimportant words by design.\n","\n","Read more here:\n","- [Understanding TF-IDF](https://monkeylearn.com/blog/what-is-tf-idf/)\n","- [TF-IDF from scratch](https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089)"],"metadata":{"id":"fWw323FK0A_U"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","sentences = [\n","    \"This is a sample sentence\",\n","    \"I am interested in politics\",\n","    \"You are a very good software engineer, engineer.\",\n","]\n","\n","# Create TfidfVectorizer.\n","# stop_words : Get rid of english stop words. \n","vectorizer = TfidfVectorizer(stop_words='english')\n","\n","# Learn vocabulary from sentences. \n","vectorizer.fit(sentences)\n","\n","# Get vocabularies.\n","vectorizer.vocabulary_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XgE6lR_b0Aa3","executionInfo":{"status":"ok","timestamp":1664364671193,"user_tz":-120,"elapsed":369,"user":{"displayName":"Esben Kran","userId":"05753607224872913825"}},"outputId":"9ad292f8-e206-44d4-80c4-b3f1b6ec0375"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'sample': 4,\n"," 'sentence': 5,\n"," 'interested': 2,\n"," 'politics': 3,\n"," 'good': 1,\n"," 'software': 6,\n"," 'engineer': 0}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# Transform to document-term matrix\n","vector_spaces = vectorizer.transform(sentences)\n","vector_spaces.toarray()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dB8LII2N3W05","executionInfo":{"status":"ok","timestamp":1664364678531,"user_tz":-120,"elapsed":373,"user":{"displayName":"Esben Kran","userId":"05753607224872913825"}},"outputId":"97fe1151-80d1-4454-b25c-6a651e8b2560"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.        , 0.        , 0.        , 0.70710678,\n","        0.70710678, 0.        ],\n","       [0.        , 0.        , 0.70710678, 0.70710678, 0.        ,\n","        0.        , 0.        ],\n","       [0.81649658, 0.40824829, 0.        , 0.        , 0.        ,\n","        0.        , 0.40824829]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# Show sentences and vector space representation.\n","# \n","# (A, B) C\n","# A : Document Index\n","# B : Specific word-vector index\n","# C : TF-IDF score\n","for i, v in zip(sentences, vector_spaces):\n","    print(i)\n","    print(v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3izpscE63YnM","executionInfo":{"status":"ok","timestamp":1664364686616,"user_tz":-120,"elapsed":241,"user":{"displayName":"Esben Kran","userId":"05753607224872913825"}},"outputId":"51fa7f48-22ad-4182-a7df-9db13258bdf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This is a sample sentence\n","  (0, 5)\t0.7071067811865476\n","  (0, 4)\t0.7071067811865476\n","I am interested in politics\n","  (0, 3)\t0.7071067811865476\n","  (0, 2)\t0.7071067811865476\n","You are a very good software engineer, engineer.\n","  (0, 6)\t0.40824829046386296\n","  (0, 1)\t0.40824829046386296\n","  (0, 0)\t0.8164965809277259\n"]}]},{"cell_type":"markdown","source":["## Calculate embedding of words in the text\n","\n","You can use word embeddings to compare how close words are in meaning (semantics). Imagine all the words as points in a 2D coordinate system, then `Royalty` and `Queen` are closer than `Royalty` and `Dog`.\n","\n","Read more here:\n","- [Introduction to Word Embedding and Word2Vec](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)\n","- [Introduction to Word Embedding](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)\n","- [Word Embedding](https://en.wikipedia.org/wiki/Word_embedding)\n","- [12.1: What is word2ve? â€” Programming with Text](https://www.youtube.com/watch?v=LSS_bos_TPI&t=293s)"],"metadata":{"id":"AU844ZMj3gIh"}},{"cell_type":"code","source":["from gensim.test.utils import common_texts, get_tmpfile\n","from gensim.models import Word2Vec\n","\n","# Get document data.\n","common_texts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4D9Cgxu3iuW","executionInfo":{"status":"ok","timestamp":1664364725699,"user_tz":-120,"elapsed":841,"user":{"displayName":"Esben Kran","userId":"05753607224872913825"}},"outputId":"480308e8-21b2-4717-8b9f-449b9c438899"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['human', 'interface', 'computer'],\n"," ['survey', 'user', 'computer', 'system', 'response', 'time'],\n"," ['eps', 'user', 'interface', 'system'],\n"," ['system', 'human', 'system', 'eps'],\n"," ['user', 'response', 'time'],\n"," ['trees'],\n"," ['graph', 'trees'],\n"," ['graph', 'minors', 'trees'],\n"," ['graph', 'minors', 'survey']]"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# Word2Vec modeling. \n","model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n","\n","# Get specified vocabulary's vector. \n","model.wv[\"computer\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufkewph43j_g","executionInfo":{"status":"ok","timestamp":1664364726996,"user_tz":-120,"elapsed":255,"user":{"displayName":"Esben Kran","userId":"05753607224872913825"}},"outputId":"091666a9-f30a-4c0d-c65b-425a0f6bab63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"]},{"output_type":"execute_result","data":{"text/plain":["array([-2.6313041e-03,  1.6538294e-03,  4.6289808e-04, -7.5920334e-04,\n","       -3.6283568e-03, -2.6506723e-03,  4.3202299e-03,  3.9012234e-03,\n","        5.4888282e-04,  3.4330352e-03,  1.7413682e-03, -1.4366965e-03,\n","       -2.1586919e-03, -2.5640775e-03, -4.6938271e-03, -3.0624846e-04,\n","        1.7438885e-03, -4.2526140e-03, -3.7460853e-03,  3.2590211e-03,\n","        3.0387915e-03, -3.2021464e-03,  1.8485422e-03, -4.9046022e-03,\n","       -4.1450812e-03, -1.5228360e-03, -3.4953225e-03, -1.6744386e-03,\n","        1.7121847e-04,  4.1132323e-03,  4.3965699e-03, -3.7769366e-03,\n","        4.3228897e-03, -1.7645077e-03,  2.8583778e-03, -3.2301315e-03,\n","       -2.6300168e-03, -1.3739102e-03, -2.4289147e-03,  2.9276155e-03,\n","        2.3178912e-03, -3.5281274e-03,  6.2511890e-04, -4.9543008e-03,\n","        1.6058442e-03,  1.6891175e-04, -4.9381829e-03,  2.9473209e-03,\n","        4.7533633e-03,  3.0923262e-03, -2.5990247e-03,  1.5995167e-03,\n","        1.3188375e-03, -3.1465988e-03, -1.3249181e-03,  4.7159302e-03,\n","       -1.1547589e-03,  1.6565455e-04, -6.1017531e-04,  1.2538077e-03,\n","       -2.1405055e-03,  2.4652726e-03,  1.4417405e-03,  4.5887455e-03,\n","       -1.6492791e-04,  2.2983858e-03,  3.2014686e-03,  1.3946992e-03,\n","       -3.0266962e-03, -1.0072148e-03,  8.9560973e-04,  1.6320060e-03,\n","       -7.5718024e-05,  2.2409807e-03,  1.9147879e-03, -1.9999160e-03,\n","        3.0584543e-04, -3.7527280e-03,  4.4680140e-03,  4.1332063e-03,\n","        2.5294705e-03, -1.1361731e-03,  3.6140929e-03,  1.9041498e-04,\n","       -3.5369287e-03,  3.4152453e-03, -2.2023160e-03,  4.9174111e-03,\n","        3.1963343e-04,  1.5896369e-03, -4.5608049e-03,  6.8927807e-04,\n","       -9.0652856e-04,  4.5641034e-05, -4.7548879e-03, -8.0534810e-04,\n","       -1.4370380e-03, -4.2601964e-03, -8.1923336e-04,  3.6247869e-03],\n","      dtype=float32)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# Get most similar words of \"computer\"\n","model.wv.similarity(\"computer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tobuqnah3kfu","executionInfo":{"status":"ok","timestamp":1664364733855,"user_tz":-120,"elapsed":296,"user":{"displayName":"Esben Kran","userId":"05753607224872913825"}},"outputId":"fc8c2f53-bb11-4d35-b45c-b0992fe90c7b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('time', 0.13495305180549622),\n"," ('survey', 0.05568737909197807),\n"," ('minors', 0.042579300701618195),\n"," ('human', 0.03648962825536728),\n"," ('trees', 0.029978659003973007),\n"," ('graph', -0.026356622576713562),\n"," ('interface', -0.061476483941078186),\n"," ('user', -0.09933125227689743),\n"," ('system', -0.10445401072502136),\n"," ('response', -0.10940004885196686)]"]},"metadata":{},"execution_count":31}]}]}